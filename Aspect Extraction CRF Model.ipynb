{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating List of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text dataset\n",
      "Generated list of sentences..\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "print('Processing text dataset')\n",
    "\n",
    "tree = ET.parse(\"/home/jeet/Academics/CS671/Project/Restaurants_Train.xml\")\n",
    "corpus = tree.getroot()\n",
    "sentences = [] # List of sentences.\n",
    "raw_data = corpus.findall('.//sentence')\n",
    "for sent in raw_data:\n",
    "    sentences.append(sent.find('text').text)\n",
    "\n",
    "print ('Generated list of sentences..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexing Aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GT 730M (CNMeM is disabled, cuDNN 5103)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Shape of output tensor:', (3044, 69))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:12: FutureWarning: The behavior of this method will change in future versions.  Use specific 'len(elem)' or 'elem is not None' test instead.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "import numpy as np\n",
    "\n",
    "train_out= np.zeros(shape=(3044,69))\n",
    "i=0\n",
    "for output in raw_data:\n",
    "    s = text_to_word_sequence(output.find('text').text, lower=False)\n",
    "    indices = np.zeros(69)\n",
    "    \n",
    "    aspectTerms = output.find('aspectTerms')\n",
    "    if (aspectTerms):\n",
    "        aspectTerm = aspectTerms.findall('aspectTerm')\n",
    "        if (aspectTerm):\n",
    "            for aspect_term in aspectTerm:\n",
    "                try:\n",
    "                    indices[s.index(aspect_term.attrib['term'])] = 1\n",
    "#                     print (indices)\n",
    "                except:\n",
    "                    continue\n",
    "    train_out[i] = indices\n",
    "    i=i+1\n",
    "\n",
    "print (\"Shape of output tensor:\", train_out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Defining input data for CRF Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_input = []\n",
    "i = 0\n",
    "for sent in sentences:\n",
    "    tuple_sent = []\n",
    "    word_token = text_to_word_sequence(sent, lower=False)\n",
    "    j = 0\n",
    "    for word in word_token:\n",
    "        input_tuple = ()\n",
    "        input_tuple = input_tuple + (word.decode('UTF-8'),)\n",
    "        if train_out[i][j] == 0:\n",
    "            input_tuple = input_tuple + ('NA',)\n",
    "        else:\n",
    "            input_tuple = input_tuple + ('A',)\n",
    "        tuple_sent.append(input_tuple)\n",
    "        j=j+1\n",
    "    train_input.append(tuple_sent)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(u'But', 'NA'), (u'the', 'NA'), (u'staff', 'A'), (u'was', 'NA'), (u'so', 'NA'), (u'horrible', 'NA'), (u'to', 'NA'), (u'us', 'NA')], [(u'To', 'NA'), (u'be', 'NA'), (u'completely', 'NA'), (u'fair', 'NA'), (u'the', 'NA'), (u'only', 'NA'), (u'redeeming', 'NA'), (u'factor', 'NA'), (u'was', 'NA'), (u'the', 'NA'), (u'food', 'A'), (u'which', 'NA'), (u'was', 'NA'), (u'above', 'NA'), (u'average', 'NA'), (u'but', 'NA'), (u\"couldn't\", 'NA'), (u'make', 'NA'), (u'up', 'NA'), (u'for', 'NA'), (u'all', 'NA'), (u'the', 'NA'), (u'other', 'NA'), (u'deficiencies', 'NA'), (u'of', 'NA'), (u'Teodora', 'NA')], [(u'The', 'NA'), (u'food', 'A'), (u'is', 'NA'), (u'uniformly', 'NA'), (u'exceptional', 'NA'), (u'with', 'NA'), (u'a', 'NA'), (u'very', 'NA'), (u'capable', 'NA'), (u'kitchen', 'A'), (u'which', 'NA'), (u'will', 'NA'), (u'proudly', 'NA'), (u'whip', 'NA'), (u'up', 'NA'), (u'whatever', 'NA'), (u'you', 'NA'), (u'feel', 'NA'), (u'like', 'NA'), (u'eating', 'NA'), (u'whether', 'NA'), (u\"it's\", 'NA'), (u'on', 'NA'), (u'the', 'NA'), (u'menu', 'A'), (u'or', 'NA'), (u'not', 'NA')], [(u'Where', 'NA'), (u'Gabriela', 'NA'), (u'personaly', 'NA'), (u'greets', 'NA'), (u'you', 'NA'), (u'and', 'NA'), (u'recommends', 'NA'), (u'you', 'NA'), (u'what', 'NA'), (u'to', 'NA'), (u'eat', 'NA')], [(u'For', 'NA'), (u'those', 'NA'), (u'that', 'NA'), (u'go', 'NA'), (u'once', 'NA'), (u'and', 'NA'), (u\"don't\", 'NA'), (u'enjoy', 'NA'), (u'it', 'NA'), (u'all', 'NA'), (u'I', 'NA'), (u'can', 'NA'), (u'say', 'NA'), (u'is', 'NA'), (u'that', 'NA'), (u'they', 'NA'), (u'just', 'NA'), (u\"don't\", 'NA'), (u'get', 'NA'), (u'it', 'NA')]]\n"
     ]
    }
   ],
   "source": [
    "print train_input[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = train_input[:2739]\n",
    "test_data = train_input[2739:]\n",
    "true_test = sentences[2739:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.tag import CRFTagger\n",
    "ct = CRFTagger()\n",
    "\n",
    "ct.train(train_data,'model_Crf_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "must be unicode, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-57c19df780be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag_sents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/nltk/tag/crf.pyc\u001b[0m in \u001b[0;36mtag_sents\u001b[0;34m(self, sents)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtokens\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feature_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tagger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/nltk/tag/crf.pyc\u001b[0m in \u001b[0;36m_get_features\u001b[0;34m(self, tokens, idx)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;31m# Punctuation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mpunc_cat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Pc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Pd\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Ps\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Pe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Pi\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Pf\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Po\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0municodedata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpunc_cat\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m             \u001b[0mfeature_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'PUNCTUATION'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/nltk/tag/crf.pyc\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m((x,))\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;31m# Punctuation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mpunc_cat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Pc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Pd\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Ps\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Pe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Pi\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Pf\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Po\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0municodedata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpunc_cat\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m             \u001b[0mfeature_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'PUNCTUATION'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: must be unicode, not str"
     ]
    }
   ],
   "source": [
    "ct.tag_sents(true_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
